{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af4351ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Model:\n",
      "MAE: 23.39, R²: 0.75\n",
      "\n",
      "Random Forest Model:\n",
      "MAE: 24.25, R²: 0.74\n",
      "\n",
      "Best Random Forest Model after Hyperparameter Tuning:\n",
      "MAE: 22.78, R²: 0.75\n",
      "Best Hyperparameters: {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "\n",
      "Cross-Validation MAE for Random Forest: -26.40\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'credit_score.csv'\n",
    "credit_data = pd.read_csv(file_path)\n",
    "\n",
    "# Feature Engineering\n",
    "# Assuming the following mappings for the variables:\n",
    "# P -> R_DEBT_INCOME (debt to income ratio)\n",
    "# U -> R_SAVINGS_INCOME (savings to income ratio, as proxy for utilization ratio)\n",
    "# L -> T_CLOTHING_12 (years of account history as proxy, assuming it relates to length)\n",
    "# M -> CAT_CREDIT_CARD and CAT_MORTGAGE (Credit mix, combined into a binary feature)\n",
    "# N -> DEFAULT (as a proxy for new credit inquiries)\n",
    "\n",
    "credit_data['P'] = credit_data['R_DEBT_INCOME']\n",
    "credit_data['U'] = credit_data['R_SAVINGS_INCOME']\n",
    "credit_data['L'] = credit_data['T_CLOTHING_12']  # Using T_CLOTHING_12 as proxy for length of history\n",
    "credit_data['M'] = credit_data['CAT_CREDIT_CARD'] + credit_data['CAT_MORTGAGE']  # Sum of binary credit mix indicators\n",
    "credit_data['N'] = credit_data['DEFAULT']  # Using DEFAULT as a proxy for new credit inquiries\n",
    "\n",
    "# Normalize the features to the range 0-1\n",
    "scaler = StandardScaler()\n",
    "credit_data[['P', 'U', 'L', 'M', 'N']] = scaler.fit_transform(credit_data[['P', 'U', 'L', 'M', 'N']])\n",
    "\n",
    "# Calculate the score using the given formula\n",
    "min_score = 300\n",
    "max_score = 900\n",
    "credit_data['Predicted_Score'] = min_score + (max_score - min_score) * (0.35 * credit_data['P'] + 0.30 * (1 - credit_data['U']) + 0.15 * credit_data['L'] + 0.10 * credit_data['M'] + 0.10 * (1 - credit_data['N']))\n",
    "\n",
    "# Model Selection and Training\n",
    "X = credit_data[['P', 'U', 'L', 'M', 'N']]\n",
    "y = credit_data['CREDIT_SCORE']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Linear Regression Model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict with the linear regression model\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# Model evaluation for Linear Regression\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "# Train a Random Forest Regressor Model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict with the random forest model\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Model evaluation for Random Forest\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "# Cross-validation for Random Forest model\n",
    "cv_rf = cross_val_score(rf_model, X, y, cv=5, scoring='neg_mean_absolute_error').mean()\n",
    "\n",
    "# Grid Search for Hyperparameter Tuning of Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "y_pred_best_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "# Evaluation of the best Random Forest model\n",
    "mae_best_rf = mean_absolute_error(y_test, y_pred_best_rf)\n",
    "r2_best_rf = r2_score(y_test, y_pred_best_rf)\n",
    "\n",
    "# Displaying Results\n",
    "print(\"Linear Regression Model:\")\n",
    "print(f\"MAE: {mae_lr:.2f}, R²: {r2_lr:.2f}\")\n",
    "\n",
    "print(\"\\nRandom Forest Model:\")\n",
    "print(f\"MAE: {mae_rf:.2f}, R²: {r2_rf:.2f}\")\n",
    "\n",
    "print(\"\\nBest Random Forest Model after Hyperparameter Tuning:\")\n",
    "print(f\"MAE: {mae_best_rf:.2f}, R²: {r2_best_rf:.2f}\")\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Display cross-validation score for Random Forest\n",
    "print(f\"\\nCross-Validation MAE for Random Forest: {cv_rf:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
